{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Домашняя работа\n",
    "\n",
    "В этой работе вам предстоит с помощью encoder-decoder архитектуры, пробуя различные ее реализации, решить задачу машинного перевода.\n",
    "\n",
    "#### Наша задача - сделать свой собственный переводчик!\n",
    "\n",
    "Пока что только русско-английский:) Будем учиться на текстах описания отелей, так что при успешном выполнении этого задания у вас не возникнет проблем с выбором места для остановки в путешествии, так как все отзывы вам будут высококлассно переведены!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Что необходимо обсудить до начала работы?\n",
    "\n",
    "*как токенезовать и закодировать текст?*\n",
    "\n",
    "С токенезацией хорошо справится WordPunctTokenizer из библиотеки nltk, а вот с кодированием не все так просто, как может показаться...\n",
    "\n",
    "В наших текстах очень много редких и очень мало встречаемых слов (в каждом отеле есть своя фишка: какой-то предмет декорации или услуга, которая описывается своим словом, которое только там и встречается). Если мы будем кодировать все слова, то размер нашего словаря будет очень-очень большим.\n",
    "\n",
    "Но на одном из семинаров мы кодировали побуквенно, кажется, что тут это может помочь! Да, действительно так, но придется очень очень долго обучать модель, а путешествовать и выбрать хороший отель уже хочется, поэтому мы придем к чему-то среднему между этими подходами -  [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt) известный как __BPE__\n",
    "\n",
    "Этот алгоритм стартует с посимвольного уровня и итеративно мерджит самые встречаемые пары. И так N итераций. На выходе мы получаем самые частые последовательности символов из которых формируются слова!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "BPE - очень популярный и частоиспользуемый алгоритм в задачах NLP, поэтому есть много открытых реализаций этого алгоритма\n",
    "\n",
    "Мы уверены, что вы научились гуглить и искать полезные материалы в интернете, когда делали домашнее задание по YOLO, поэтому в этот раз просто покажем один из способов, как это можно сделать и затем в своих проектах вы можете брать этот подход и, возможно, как-то улучшать его!\n",
    "\n",
    "Тем кому очень интересно, как же все работает - заходите в файл vocab.py, очень советуем!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:04<00:00, 1821.10it/s]\n",
      "100%|██████████| 8000/8000 [00:04<00:00, 1708.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def tokenize(x):\n",
    "    return ' '.join(tokenizer.tokenize(x.lower()))\n",
    "\n",
    "\n",
    "# разбиваем и токенизируем тексты, записываем обработанные токены в файл\n",
    "with open('train.en', 'w') as f_src, open('train.ru', 'w') as f_dst:\n",
    "    for line in open('data.txt'):\n",
    "        src_line, dst_line = line.strip().split('\\t')\n",
    "        f_src.write(tokenize(src_line) + '\\n')\n",
    "        f_dst.write(tokenize(dst_line) + '\\n')\n",
    "\n",
    "# строим и применяем bpe кодирование\n",
    "bpe = {}\n",
    "for lang in ['en', 'ru']:\n",
    "    learn_bpe(open('./train.' + lang), open('bpe_rules.' + lang, 'w'), num_symbols=8000)\n",
    "    bpe[lang] = BPE(open('./bpe_rules.' + lang))\n",
    "\n",
    "    with open('train.bpe.' + lang, 'w') as f_out:\n",
    "        for line in open('train.' + lang):\n",
    "            f_out.write(bpe[lang].process_line(line.strip()) + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:35.645713Z",
     "end_time": "2023-04-27T19:59:51.358638Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Построение словарей, разбиение данных\n",
    "\n",
    "Сейчас, когда мы обучили BPE алгоритм на наших данных, построим словарь соответствия токена и его индекса, чтобы нам было затем удобно смотреть переводы и переводить новые предложения\n",
    "\n",
    "Также сделаем разбиение на train/test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:51.357969Z",
     "end_time": "2023-04-27T19:59:51.363809Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: на территории обустроена бесплатная частная парковка .\n",
      "out: free private parking is available on site .\n",
      "\n",
      "inp: кроме того , в 5 минутах ходьбы работают многочисленные бары и рестораны .\n",
      "out: guests can find many bars and restaurants within a 5 - minute walk .\n",
      "\n",
      "inp: отель san mi@@ gu@@ el расположен в центре мор@@ ели@@ и , в 750 метрах от главной площади города и кафедрального собора .\n",
      "out: hotel san miguel is located in central more@@ lia , 750 metres from the city ’ s main square and cathedral .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_inp = np.array(open('./train.bpe.ru').read().split('\\n'))\n",
    "data_out = np.array(open('./train.bpe.en').read().split('\\n'))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inp, dev_inp, train_out, dev_out = train_test_split(data_inp, data_out, test_size=3000,\n",
    "                                                          random_state=42)\n",
    "for i in range(3):\n",
    "    print('inp:', train_inp[i])\n",
    "    print('out:', train_out[i], end='\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:51.363033Z",
     "end_time": "2023-04-27T19:59:51.596279Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from vocab import Vocab\n",
    "\n",
    "inp_voc = Vocab.from_lines(train_inp)\n",
    "out_voc = Vocab.from_lines(train_out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:51.597200Z",
     "end_time": "2023-04-27T19:59:53.628244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n",
      "\n",
      "words to ids (0 = bos, 1 = eos):\n",
      "tensor([[   0, 2688, 2943, 1108,   29,    1,    1,    1],\n",
      "        [   0, 2922, 1834, 8035,   59, 3800,   29,    1],\n",
      "        [   0, 6030, 2083,   29,    1,    1,    1,    1],\n",
      "        [   0, 4927, 1870,   29,    1,    1,    1,    1],\n",
      "        [   0, 5549, 1453,   27,  592,   29,    1,    1]])\n",
      "\n",
      "back to words\n",
      "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n"
     ]
    }
   ],
   "source": [
    "# тут можно посмотреть, как работает маппинг из индекса в токен и наоборот\n",
    "batch_lines = sorted(train_inp, key=len)[5:10]\n",
    "batch_ids = inp_voc.to_matrix(batch_lines)\n",
    "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
    "\n",
    "print(\"lines\")\n",
    "print(batch_lines)\n",
    "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
    "print(batch_ids)\n",
    "print(\"\\nback to words\")\n",
    "print(batch_lines_restored)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:53.627475Z",
     "end_time": "2023-04-27T19:59:53.717000Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'-'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_voc.tokens[27]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:53.720212Z",
     "end_time": "2023-04-27T19:59:53.770032Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## За вас сделали домашнюю работу? Нет, вам самое интересное!\n",
    "\n",
    "Если вы пролистываете ноутбук и вам уже очень хочется начать писать самим - то мы вас понимаем, задание очень интересное и полезное!\n",
    "И спешим вас обрадовать, так как вы дождались и тут как раз можно проявить всю фантазию и мастерство написание нейронных сетей!\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Задание 1 (1 балла)\n",
    "В коде ниже мы представили шаблон простой encoder-decoder модели, без всяких наворотов с Attention или чем-нибудь еще. Вы можете редактировать его под себя: добавлять новые методы, новые переменные, писать на pytorch ligtning и другое.\n",
    "\n",
    "Главное - сохраните идею шаблона и сделайте его очень удобным, так как с ним еще предстоит работать!\n",
    "\n",
    "Заполните пропуски с `<YOUR CODE HERE>`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:53.725448Z",
     "end_time": "2023-04-27T19:59:53.770250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, inp_voc, out_voc, emb_size=64, hid_size=128, tf_coef=1):\n",
    "        \"\"\"\n",
    "        Базовая модель encoder-decoder архитектуры\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.inp_voc, self.out_voc = inp_voc, out_voc\n",
    "        self.hid_size = hid_size\n",
    "        self.tf_coef = tf_coef\n",
    "\n",
    "        self.emb_inp = nn.Embedding(len(inp_voc), emb_size)\n",
    "        self.emb_out = nn.Embedding(len(out_voc), emb_size)\n",
    "        self.enc0 = nn.GRU(emb_size, hid_size, batch_first=True)\n",
    "\n",
    "        self.dec_start = nn.Linear(hid_size, hid_size)\n",
    "        self.dec0 = nn.GRUCell(emb_size, hid_size)\n",
    "        self.logits = nn.Linear(hid_size, len(out_voc))\n",
    "\n",
    "    def forward(self, inp, out):\n",
    "        \"\"\" Сначала примените  encode а затем decode\"\"\"\n",
    "        initial_state = self.encode(inp)\n",
    "        return self.decode(initial_state, out)\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Считаем скрытое состояние, которое будет начальным для decode\n",
    "        :param inp: матрица входных токенов\n",
    "        :returns: скрытое представление с которого будет начинаться decode\n",
    "        \"\"\"\n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        batch_size = inp.shape[0]\n",
    "\n",
    "        enc_seq, [last_state_but_not_really] = self.enc0(inp_emb)\n",
    "        # enc_seq: [batch, time, hid_size], last_state: [batch, hid_size]\n",
    "\n",
    "        # последний токен, не последние на самом деле, так как мы делали padding, чтобы тексты были\n",
    "        # одинакового размер, поэтому подсчитать длину исходного предложения не так уж тривиально\n",
    "        lengths = (inp != self.inp_voc.eos_ix).to(torch.int64).sum(dim=1).clamp_max(inp.shape[1] - 1)\n",
    "        last_state = enc_seq[torch.arange(len(enc_seq)), lengths]\n",
    "        # ^-- shape: [batch_size, hid_size]\n",
    "\n",
    "        dec_start = self.dec_start(last_state)\n",
    "        return [dec_start]\n",
    "\n",
    "    def decode_step(self, prev_state, prev_tokens, **flags):\n",
    "        \"\"\"\n",
    "        Принимает предыдущее состояние декодера и токены, возвращает новое состояние и\n",
    "        логиты для следующих токенов\n",
    "        \"\"\"\n",
    "        prev_gru0_state = prev_state[0]\n",
    "        prev_tokens_emb = self.emb_out(prev_tokens)\n",
    "\n",
    "        new_dec_state = self.dec0(prev_tokens_emb, prev_gru0_state)\n",
    "        output_logits = self.logits(new_dec_state)\n",
    "\n",
    "        return [new_dec_state], output_logits\n",
    "\n",
    "    def decode(self, initial_state, out_tokens, **flags):\n",
    "        batch_size = out_tokens.shape[0]\n",
    "        state = initial_state\n",
    "\n",
    "        # первый символ всегда BOS\n",
    "        onehot_bos = F.one_hot(torch.full([batch_size], self.out_voc.bos_ix, dtype=torch.int64),\n",
    "                               num_classes=len(self.out_voc)).to(device=out_tokens.device)\n",
    "        first_logits = torch.log(onehot_bos.to(torch.float32) + 1e-9)\n",
    "\n",
    "        logits_sequence = [first_logits]\n",
    "        # в цикле делаем decode_step, получаем logits_sequence\n",
    "        for i in range(out_tokens.shape[1] - 1):\n",
    "            tokens = out_tokens[:, i] if random.uniform(0, 1) <= self.tf_coef else logits_sequence[-1].argmax(dim=-1)\n",
    "            state, logits = self.decode_step(state, tokens)\n",
    "            logits_sequence.append(logits)\n",
    "        return torch.stack(logits_sequence, dim=1)\n",
    "\n",
    "    def decode_inference(self, initial_state, max_len=100, **flags):\n",
    "        \"\"\" Генерим токены для перевода \"\"\"\n",
    "        batch_size, device = len(initial_state[0]), initial_state[0].device\n",
    "        state = initial_state\n",
    "        outputs = [torch.full([batch_size], self.out_voc.bos_ix, dtype=torch.int64, device=device)]\n",
    "        all_states = [initial_state]\n",
    "\n",
    "        for i in range(max_len):\n",
    "            state, logits = self.decode_step(state, outputs[-1])\n",
    "            outputs.append(logits.argmax(dim=-1))\n",
    "            all_states.append(state)\n",
    "\n",
    "        return torch.stack(outputs, dim=1), all_states\n",
    "\n",
    "    def translate_lines(self, inp_lines, **kwargs):\n",
    "        \"\"\"Функция для перевода\"\"\"\n",
    "        inp = self.inp_voc.to_matrix(inp_lines).to(device)\n",
    "        initial_state = self.encode(inp)\n",
    "        out_ids, states = self.decode_inference(initial_state, **kwargs)\n",
    "        return self.out_voc.to_lines(out_ids.cpu().numpy()), states\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:53.743641Z",
     "end_time": "2023-04-27T19:59:53.825630Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# debugging area\n",
    "model = BaseModel(inp_voc, out_voc).to(device)\n",
    "\n",
    "dummy_inp_tokens = inp_voc.to_matrix(sorted(train_inp, key=len)[5:10]).to(device)\n",
    "dummy_out_tokens = out_voc.to_matrix(sorted(train_out, key=len)[5:10]).to(device)\n",
    "\n",
    "h0 = model.encode(dummy_inp_tokens)\n",
    "h1, logits1 = model.decode_step(h0, torch.arange(len(dummy_inp_tokens), device=device))\n",
    "\n",
    "assert isinstance(h1, list) and len(h1) == len(h0)\n",
    "assert h1[0].shape == h0[0].shape and not torch.allclose(h1[0], h0[0])\n",
    "assert logits1.shape == (len(dummy_inp_tokens), len(out_voc))\n",
    "\n",
    "logits_seq = model.decode(h0, dummy_out_tokens)\n",
    "assert logits_seq.shape == (dummy_out_tokens.shape[0], dummy_out_tokens.shape[1], len(out_voc))\n",
    "\n",
    "# full forward\n",
    "logits_seq2 = model(dummy_inp_tokens, dummy_out_tokens)\n",
    "assert logits_seq2.shape == logits_seq.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:53.750613Z",
     "end_time": "2023-04-27T19:59:53.942425Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translations without training:\n",
      "castles seafood mill tyrolean interstate sukhumvit indul@@ sac@@ citad@@ jour@@ interstate ingen premises m@@ may@@ ne bolsho@@ trains matt vac@@ lle tub fa@@ gue ór@@\n",
      "castles seafood mill tyrolean interstate sukhumvit indul@@ sac@@ citad@@ jour@@ interstate ingen premises m@@ may@@ ne bolsho@@ trains matt vac@@ lle tub fa@@ gue ór@@\n",
      "polish ground fra@@ samui samui peace ming bairro ok@@ ins antique cke arno bahn@@ т fell@@ ob@@ mediter@@ campan@@ clubs award sunday short swimming swimming\n",
      "castles seafood mill tyrolean interstate sukhumvit indul@@ sac@@ citad@@ jour@@ interstate ingen premises m@@ may@@ ne bolsho@@ trains matt vac@@ lle tub fa@@ gue ór@@\n",
      "castles seafood mill tyrolean interstate sukhumvit indul@@ sac@@ citad@@ jour@@ interstate ingen premises m@@ may@@ ne bolsho@@ trains matt vac@@ lle tub fa@@ gue ór@@\n"
     ]
    }
   ],
   "source": [
    "dummy_translations, dummy_states = model.translate_lines(train_inp[5:10], max_len=25)\n",
    "print(\"Translations without training:\")\n",
    "print('\\n'.join([line for line in dummy_translations]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:59:53.945300Z",
     "end_time": "2023-04-27T19:59:53.981075Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 2 (2 балла)\n",
    "\n",
    "Тут нечего объяснять, нужно написать лосс, чтобы все училось:\n",
    "$$ L = {\\frac1{|D|}} \\sum_{X, Y \\in D} \\sum_{y_t \\in Y} - \\log p(y_t \\mid y_1, \\dots, y_{t-1}, X, \\theta) $$\n",
    "\n",
    "где $|D|$ это суммарная длина всех предложений включая все токены: BOS, EOS но не включая падинг"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def loss_function(model, inp, out, **flags):\n",
    "    \"\"\"\n",
    "    Функция для подсчета лосса\n",
    "    :param inp: input tokens matrix, int32[batch, time]\n",
    "    :param out: reference tokens matrix, int32[batch, time]\n",
    "\n",
    "    Для того чтобы пройти тесты, ваша функция должна\n",
    "    * учитывать в loss первый EOS, но НЕ учитывать последующие\n",
    "    * разделить loss на длину входящей последовательности (use voc.compute_mask)\n",
    "    \"\"\"\n",
    "    mask = model.out_voc.compute_mask(out) # [batch_size, out_len]\n",
    "    targets_1hot = F.one_hot(out, len(model.out_voc)).to(torch.float32)\n",
    "\n",
    "    # outputs of the model, [batch_size, out_len, num_tokens]\n",
    "    logits_seq = model(inp, out)\n",
    "\n",
    "    # log-probabilities всех токенов на всех шагах\n",
    "    logprobs_seq = torch.log(torch.softmax(logits_seq, dim=-1)) # [batch_size, out_len, num_tokens]\n",
    "\n",
    "    # log-probabilities для верных ответов\n",
    "    logp_out = (logprobs_seq * targets_1hot).sum(dim=-1) # [batch_size, out_len]\n",
    "    # нужно обойтись только векторными операциями без for\n",
    "\n",
    "    # cross-entropy по всем токенам где mask == True\n",
    "    return -1 / mask.sum() * torch.where(mask, logp_out, torch.tensor(0, dtype=torch.float32, device=device)).sum() # тут должен получиться скаляр!"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T20:18:31.344739Z",
     "end_time": "2023-04-27T20:18:31.359997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "where() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other, *, Tensor out)\n * (Tensor condition, Number self, Tensor other)\n * (Tensor condition, Tensor input, Number other)\n * (Tensor condition, Number self, Number other)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dummy_loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdummy_inp_tokens\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdummy_out_tokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss:\u001B[39m\u001B[38;5;124m\"\u001B[39m, dummy_loss)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m np\u001B[38;5;241m.\u001B[39mallclose(dummy_loss\u001B[38;5;241m.\u001B[39mitem(), \u001B[38;5;241m7.5\u001B[39m, rtol\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, atol\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[11], line 25\u001B[0m, in \u001B[0;36mloss_function\u001B[0;34m(model, inp, out, **flags)\u001B[0m\n\u001B[1;32m     21\u001B[0m logp_out \u001B[38;5;241m=\u001B[39m (logprobs_seq \u001B[38;5;241m*\u001B[39m targets_1hot)\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;66;03m# [batch_size, out_len]\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# нужно обойтись только векторными операциями без for\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# cross-entropy по всем токенам где mask == True\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m mask\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;241m*\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogp_out\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msum()\n",
      "\u001B[0;31mTypeError\u001B[0m: where() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other, *, Tensor out)\n * (Tensor condition, Number self, Tensor other)\n * (Tensor condition, Tensor input, Number other)\n * (Tensor condition, Number self, Number other)\n"
     ]
    }
   ],
   "source": [
    "dummy_loss = loss_function(model, dummy_inp_tokens, dummy_out_tokens)\n",
    "print(\"Loss:\", dummy_loss)\n",
    "assert np.allclose(dummy_loss.item(), 7.5, rtol=0.1, atol=0.1)\n",
    "\n",
    "# test autograd\n",
    "dummy_loss.backward()\n",
    "for name, param in model.named_parameters():\n",
    "    assert param.grad is not None and abs(param.grad.max()) != 0, f\"Param {name} received no gradients\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Метрика: BLEU\n",
    "\n",
    "Для оценки машинного перевода обычно используется метрика [BLEU](https://en.wikipedia.org/wiki/BLEU). Она просто считает кол-во правильно предсказанных n-grams для n=1,2,3,4 и потом берет геометрическое среднее для полученных значений."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "\n",
    "def compute_bleu(model, inp_lines, out_lines, bpe_sep='@@ ', **flags):\n",
    "    \"\"\"\n",
    "    пример как считать метрику BLEU. Вы можете изменять вход и выход,\n",
    "    как вам удобно, главное оставьте логику ее подсчета!!!\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "        translations = [line.replace(bpe_sep, '') for line in translations]\n",
    "        actual = [line.replace(bpe_sep, '') for line in out_lines]\n",
    "        return corpus_bleu(\n",
    "            [[ref.split()] for ref in actual],\n",
    "            [trans.split() for trans in translations],\n",
    "            smoothing_function=lambda precisions, **kw: [p + 1.0 / p.denominator for p in precisions]\n",
    "        ) * 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T20:18:59.430730Z",
     "end_time": "2023-04-27T20:18:59.435879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compute_bleu(model, dev_inp, dev_out)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training loop (1 балл)\n",
    "\n",
    "Нужно просто написать цикл обучения и подсчитать метрики! И пройти assert по качеству"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "where() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other, *, Tensor out)\n * (Tensor condition, Number self, Tensor other)\n * (Tensor condition, Tensor input, Number other)\n * (Tensor condition, Number self, Number other)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m out \u001B[38;5;241m=\u001B[39m out_voc\u001B[38;5;241m.\u001B[39mto_matrix(train_out[idx])\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     22\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 23\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     25\u001B[0m opt\u001B[38;5;241m.\u001B[39mstep()\n",
      "Cell \u001B[0;32mIn[11], line 25\u001B[0m, in \u001B[0;36mloss_function\u001B[0;34m(model, inp, out, **flags)\u001B[0m\n\u001B[1;32m     21\u001B[0m logp_out \u001B[38;5;241m=\u001B[39m (logprobs_seq \u001B[38;5;241m*\u001B[39m targets_1hot)\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;66;03m# [batch_size, out_len]\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# нужно обойтись только векторными операциями без for\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# cross-entropy по всем токенам где mask == True\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m mask\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;241m*\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogp_out\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msum()\n",
      "\u001B[0;31mTypeError\u001B[0m: where() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other, *, Tensor out)\n * (Tensor condition, Number self, Tensor other)\n * (Tensor condition, Tensor input, Number other)\n * (Tensor condition, Number self, Number other)\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "metrics = {'train_loss': [], 'dev_bleu': []}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = BaseModel(inp_voc, out_voc).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "batch_size = 32\n",
    "\n",
    "num_iter = 1\n",
    "\n",
    "last_bleu = 0\n",
    "\n",
    "with trange(num_iter) as t:\n",
    "    for it in t:\n",
    "        idx = np.random.randint(0, len(train_inp), batch_size)\n",
    "        inp = inp_voc.to_matrix(train_inp[idx]).to(device)\n",
    "        out = out_voc.to_matrix(train_out[idx]).to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = loss_function(model, inp, out)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if it % 500 == 0:\n",
    "            metrics['train_loss'].append(loss.item())\n",
    "            last_bleu = compute_bleu(model, dev_inp, dev_out)\n",
    "            metrics['dev_bleu'].append(last_bleu)\n",
    "\n",
    "        t.set_postfix(loss=loss.item(), bleu=last_bleu)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert np.mean(metrics['dev_bleu'][-10:], axis=0)[1] > 15, \"Ты можешь больше! попробуй еще раз)\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for inp_line, trans_line in zip(dev_inp[::500], model.translate_lines(dev_inp[::500])[0]):\n",
    "    print(inp_line)\n",
    "    print(trans_line)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attention is all you need"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 3\n",
    "\n",
    "В этом разделе мы хотим, чтобы вы усовершенствовали базовую модель\n",
    "\n",
    "\n",
    "Сначала напишем слой Attention, а потом внедрим его в уже существующий шаблон"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Attention layer (1 points)\n",
    "\n",
    "На вход подается скрытые состояния encoder $h^e_0, h^e_1, h^e_2, ..., h^e_T$ и предыдущие состояние декодера $h^d$,\n",
    "\n",
    "* Считаем логиты:\n",
    "$$a_t = linear_{out}(tanh(linear_{e}(h^e_t) + linear_{d}(h_d)))$$\n",
    "* Получаем вероятности из логитов:\n",
    "$$ p_t = {{e ^ {a_t}} \\over { \\sum_\\tau e^{a_\\tau} }} $$\n",
    "\n",
    "* Взвешиваем состояния энкодера с полученными вероятностями\n",
    "$$ attn = \\sum_t p_t \\cdot h^e_t $$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, enc_size, dec_size, hid_size):\n",
    "        super().__init__()\n",
    "        self.enc_size = enc_size\n",
    "        self.dec_size = dec_size\n",
    "        self.hid_size = hid_size\n",
    "\n",
    "        # опишите все слои, которые нужны Attention\n",
    "        self.linear_enc = nn.Linear(enc_size, hid_size)\n",
    "        self.linear_dec = nn.Linear(dec_size, hid_size)\n",
    "        self.linear_out = nn.Linear(hid_size, 1)\n",
    "\n",
    "    def forward(self, enc, dec, inp_mask):\n",
    "        \"\"\"\n",
    "        Подсчитываем attention ответ and веса\n",
    "        :param enc: [batch_size, ninp, enc_size]\n",
    "        :param dec: decode state[batch_size, dec_size]\n",
    "        :param inp_mask: маска, 0 там где pading [batch_size, ninp]\n",
    "        :returns: attn[batch_size, enc_size], probs[batch_size, ninp]\n",
    "        \"\"\"\n",
    "\n",
    "        # считаем логиты\n",
    "        logits = self.linear_out(torch.tanh(self.linear_enc(enc) + self.linear_dec(dec).unsqueeze(dim=1))).squeeze()\n",
    "\n",
    "        # Применим маску - если значение маски 0, логиты должны быть -inf или -1e9\n",
    "        # Лучше использовать torch.where\n",
    "        logits = torch.where(inp_mask, logits, torch.tensor(-1e9, dtype=torch.float32, device=device))\n",
    "\n",
    "        # Примените softmax\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Подсчитайте выход attention используя enc состояния и вероятностями\n",
    "        attn = torch.sum(probs.unsqueeze(dim=-1) * enc, axis=1)\n",
    "\n",
    "        return attn, probs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T20:18:44.929310Z",
     "end_time": "2023-04-27T20:18:44.933195Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seq2seq model with attention (2 points)\n",
    "\n",
    "Теперь вы можете использовать уровень внимания для построения сети. Самый простой способ реализовать внимание - использовать его на этапе декодирования:\n",
    "\n",
    "\n",
    "На каждом шаге используйте предыдущее состояние декодера, и написанный слой Attention\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "class AttentiveModel(BaseModel):\n",
    "    def __init__(self, inp_voc, out_voc, emb_size=64, hid_size=128, attn_size=128, tf_coef=1):\n",
    "        \"\"\"Переводчик с Attention\"\"\"\n",
    "        super().__init__(inp_voc, out_voc, emb_size=emb_size, hid_size=hid_size, tf_coef=tf_coef)\n",
    "\n",
    "        self.attn = AttentionLayer(hid_size, hid_size, attn_size)\n",
    "        self.dec0 = nn.GRUCell(emb_size + hid_size, hid_size)\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Считаем скрытые состояния, которые используем в decode\n",
    "        :param inp: матрица входных токенов\n",
    "        \"\"\"\n",
    "\n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        batch_size = inp.shape[0]\n",
    "\n",
    "        # делаем encode\n",
    "        enc_seq, last_state_but_not_really = self.enc0(inp_emb)\n",
    "        lengths = (inp != self.inp_voc.eos_ix).to(torch.int64).sum(dim=1).clamp_max(inp.shape[1] - 1)\n",
    "        last_state = enc_seq[torch.arange(len(enc_seq)), lengths]\n",
    "        dec_start = self.dec_start(last_state)\n",
    "\n",
    "        # apply attention layer from initial decoder hidden state\n",
    "        # применяем attention слой для скрытых состояний\n",
    "        mask = self.inp_voc.compute_mask(inp)\n",
    "        first_attn_probas = self.attn(enc_seq, dec_start, mask)[1]\n",
    "\n",
    "        # Для декодера нужно вернуть:\n",
    "        # - начальное состояние для RNN декодера\n",
    "        # - последовательность скрытых состояний encoder, маска для них\n",
    "        # - последним передаем вероятности слоя attention\n",
    "\n",
    "        first_state = [dec_start, enc_seq, mask, first_attn_probas]\n",
    "        return first_state\n",
    "\n",
    "    def decode_step(self, prev_state, prev_tokens, **flags):\n",
    "        \"\"\"\n",
    "        Принимает предыдущее состояние декодера и токены, возвращает новое состояние и логиты для следующих токенов\n",
    "        :param prev_state: список тензоров предыдущих состояний декодера\n",
    "        :param prev_tokens: предыдущие выходные токены [batch_size]\n",
    "        :return: список тензоров состояния следующего декодера, тензор логитов [batch, n_tokens]\n",
    "        \"\"\"\n",
    "        prev_gru0_state, enc_seq, mask, _ = prev_state\n",
    "        prev_tokens_emb = self.emb_out(prev_tokens)\n",
    "\n",
    "        attn, attn_probas = self.attn(enc_seq, prev_gru0_state, mask)\n",
    "\n",
    "        new_dec_state = self.dec0(torch.cat((prev_tokens_emb, attn), dim=-1), prev_gru0_state)\n",
    "        output_logits = self.logits(new_dec_state)\n",
    "\n",
    "        new_dec_state = [new_dec_state, enc_seq, mask, attn_probas]\n",
    "        return [new_dec_state, output_logits]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T20:18:47.251705Z",
     "end_time": "2023-04-27T20:18:47.265364Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обучение модели (1 points)\n",
    "\n",
    "Нужно обучить AttentiveModel и пройти assert по качеству"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/25000 [00:41<14:15:05,  2.05s/it, bleu=0.00231, loss=6.23]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m out \u001B[38;5;241m=\u001B[39m out_voc\u001B[38;5;241m.\u001B[39mto_matrix(train_out[idx])\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     18\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 19\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     21\u001B[0m opt\u001B[38;5;241m.\u001B[39mstep()\n",
      "Cell \u001B[0;32mIn[42], line 15\u001B[0m, in \u001B[0;36mloss_function\u001B[0;34m(model, inp, out, **flags)\u001B[0m\n\u001B[1;32m     12\u001B[0m targets_1hot \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mone_hot(out, \u001B[38;5;28mlen\u001B[39m(model\u001B[38;5;241m.\u001B[39mout_voc))\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# outputs of the model, [batch_size, out_len, num_tokens]\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m logits_seq \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# log-probabilities всех токенов на всех шагах\u001B[39;00m\n\u001B[1;32m     18\u001B[0m logprobs_seq \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlog(torch\u001B[38;5;241m.\u001B[39msoftmax(logits_seq, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;66;03m# [batch_size, out_len, num_tokens]\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[8], line 25\u001B[0m, in \u001B[0;36mBaseModel.forward\u001B[0;34m(self, inp, out)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m\"\"\" Сначала примените  encode а затем decode\"\"\"\u001B[39;00m\n\u001B[1;32m     24\u001B[0m initial_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode(inp)\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43minitial_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 75\u001B[0m, in \u001B[0;36mBaseModel.decode\u001B[0;34m(self, initial_state, out_tokens, **flags)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(out_tokens\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     74\u001B[0m     tokens \u001B[38;5;241m=\u001B[39m out_tokens[:, i] \u001B[38;5;28;01mif\u001B[39;00m random\u001B[38;5;241m.\u001B[39muniform(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtf_coef \u001B[38;5;28;01melse\u001B[39;00m logits_sequence[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 75\u001B[0m     state, logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m     logits_sequence\u001B[38;5;241m.\u001B[39mappend(logits)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mstack(logits_sequence, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[44], line 47\u001B[0m, in \u001B[0;36mAttentiveModel.decode_step\u001B[0;34m(self, prev_state, prev_tokens, **flags)\u001B[0m\n\u001B[1;32m     44\u001B[0m prev_gru0_state, enc_seq, mask, _ \u001B[38;5;241m=\u001B[39m prev_state\n\u001B[1;32m     45\u001B[0m prev_tokens_emb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39memb_out(prev_tokens)\n\u001B[0;32m---> 47\u001B[0m attn, attn_probas \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\u001B[43menc_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprev_gru0_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m new_dec_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdec0(torch\u001B[38;5;241m.\u001B[39mcat((prev_tokens_emb, attn), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m), prev_gru0_state)\n\u001B[1;32m     50\u001B[0m output_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogits(new_dec_state)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[43], line 23\u001B[0m, in \u001B[0;36mAttentionLayer.forward\u001B[0;34m(self, enc, dec, inp_mask)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03mПодсчитываем attention ответ and веса\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m:param enc: [batch_size, ninp, enc_size]\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m:returns: attn[batch_size, enc_size], probs[batch_size, ninp]\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# считаем логиты\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_out(torch\u001B[38;5;241m.\u001B[39mtanh(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_enc\u001B[49m\u001B[43m(\u001B[49m\u001B[43menc\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_dec(dec)\u001B[38;5;241m.\u001B[39munsqueeze(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)))\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Применим маску - если значение маски 0, логиты должны быть -inf или -1e9\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Лучше использовать torch.where\u001B[39;00m\n\u001B[1;32m     27\u001B[0m logits \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(inp_mask, logits, torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1e9\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32, device\u001B[38;5;241m=\u001B[39mdevice))\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "metrics = {'train_loss': [], 'dev_bleu': []}\n",
    "\n",
    "model = AttentiveModel(inp_voc, out_voc).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "batch_size = 32\n",
    "\n",
    "num_iter = 25000\n",
    "\n",
    "last_bleu = 0\n",
    "\n",
    "with trange(num_iter) as t:\n",
    "    for it in t:\n",
    "        idx = np.random.randint(0, len(train_inp), batch_size)\n",
    "        inp = inp_voc.to_matrix(train_inp[idx]).to(device)\n",
    "        out = out_voc.to_matrix(train_out[idx]).to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = loss_function(model, inp, out)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        t.set_postfix(loss=loss.item(), bleu=last_bleu)\n",
    "\n",
    "        if it % 500 == 0:\n",
    "            metrics['train_loss'].append(loss.item())\n",
    "            last_bleu = compute_bleu(model, dev_inp, dev_out)\n",
    "            metrics['dev_bleu'].append(last_bleu)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T20:06:43.385180Z",
     "end_time": "2023-04-27T20:06:43.427081Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "< YOUR\n",
    "CODE: training\n",
    "loop >"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "< YOUR\n",
    "CODE: measure\n",
    "final\n",
    "BLEU >\n",
    "\n",
    "assert np.mean(metrics['dev_bleu'][-10:], axis=0)[1] > 23, \"Ты можешь больше! попробуй еще раз)\"\n",
    "y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "< YOUR\n",
    "CODE: print\n",
    "translate\n",
    "examples >"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Как решать NLP задачу? Дообучить модель из huggingface\n",
    "\n",
    "Как мы видели на последнем семинаре в прошлом модуле можно получить отлично качество генерации текста, написав при этом не очень много строк кода, может быть попробовать тут также?)\n",
    "\n",
    "Это отличная идея!\n",
    "\n",
    "### Задание 4 (2 points)\n",
    "\n",
    "Нужно взять модель из [huggingface](https://huggingface.co/models?pipeline_tag=translation&sort=downloads), дообучить на наших данных и посмотреть, какое качество"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import < YOUR\n",
    "CODE\n",
    "HERE >\n",
    "\n",
    "tokenizer = < YOUR\n",
    "CODE\n",
    "HERE >\n",
    "model = < YOUR\n",
    "CODE\n",
    "HERE >\n",
    "# обычно есть How to Get Started With the Model и там показано, как инициализировать модель"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "< YOUR\n",
    "CODE\n",
    "HERE: train\n",
    "loop >\n",
    "# можно взять ваш из предыдущих пунктов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "< YOUR\n",
    "CODE\n",
    "HERE: compute_bleu >\n",
    "# аналогично прошлым пунктам\n",
    "\n",
    "assert np.mean(metrics['dev_bleu'][-10:], axis=0)[1] > 27, \"Ты можешь больше! попробуй еще раз)\""
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "edk_oVg0lrtW"
   ],
   "name": "practice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
